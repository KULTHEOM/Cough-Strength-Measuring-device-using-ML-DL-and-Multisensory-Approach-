{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)  # Keep spatial size constant\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layers with probability 0.5\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d(output_size=(1, 1))  # Global max pooling\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=32)  # Match the output of global pool\n",
    "        self.fc = nn.Linear(in_features=32, out_features=3)  # Output layer for 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.global_pool(x)  # Global max pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.fc(x)  # Dense layer\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Function\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.stats import entropy\n",
    "class CoughFeatureExtractor:\n",
    "    def __init__(self, sample_rate=48000):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def bandpass_filter(self, audio, lowcut=150, highcut=2000):\n",
    "        \"\"\"Apply bandpass filter with handling for short audio\"\"\"\n",
    "        if len(audio) < 54:  # If audio is shorter than minimum required length\n",
    "            # Pad the audio to minimum length\n",
    "            audio = np.pad(audio, (0, 54 - len(audio)), mode='constant')\n",
    "            \n",
    "        nyquist = self.sample_rate // 2\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(4, [low, high], btype='band')\n",
    "        \n",
    "        try:\n",
    "            filtered = filtfilt(b, a, audio)\n",
    "            return filtered\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Audio length {len(audio)} was too short for filtering\")\n",
    "            return audio  # Return original audio if filtering fails\n",
    "    \n",
    "    def onset_detection(self, audio):\n",
    "        \"\"\"Detect onsets in the audio signal\"\"\"\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=self.sample_rate)\n",
    "        onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=self.sample_rate)\n",
    "        return onset_frames\n",
    "    \n",
    "    def calculate_shannon_entropy(self, signal):\n",
    "        \"\"\"Calculate Shannon entropy of the signal\"\"\"\n",
    "        histogram, _ = np.histogram(signal, bins=256, range=(-1.0, 1.0), density=True)\n",
    "        histogram = histogram + 1e-10  # Add small epsilon to avoid log(0)\n",
    "        return entropy(histogram, base=2)\n",
    "    \n",
    "    def calculate_mfcc_features(self, audio_path):\n",
    "        \"\"\"Calculate MFCC features and Shannon entropy with handling for short audio\"\"\"\n",
    "        try:\n",
    "            # Load and resample audio to 16kHz as per paper\n",
    "            audio, orig_sr = sf.read(audio_path)\n",
    "            \n",
    "            # Convert to mono if stereo\n",
    "            if len(audio.shape) > 1:\n",
    "                audio = np.mean(audio, axis=1)\n",
    "            \n",
    "            if orig_sr != self.sample_rate:\n",
    "                audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=self.sample_rate)\n",
    "            \n",
    "            # Ensure minimum length (100ms)\n",
    "            min_samples = int(0.1 * self.sample_rate)  # 100ms worth of samples\n",
    "            if len(audio) < min_samples:\n",
    "                audio = np.pad(audio, (0, min_samples - len(audio)), mode='constant')\n",
    "            \n",
    "            # Apply preprocessing\n",
    "            audio = audio / (np.max(np.abs(audio)) + 1e-10)  # Normalize with small epsilon\n",
    "            audio = self.bandpass_filter(audio)  # Bandpass filter\n",
    "            \n",
    "            # Onset detection\n",
    "            onset_frames = self.onset_detection(audio)\n",
    "            if len(onset_frames) == 0:\n",
    "                print(\"No significant onsets detected, skipping audio.\")\n",
    "                return None, None\n",
    "            \n",
    "            # Calculate frame length and hop length (5ms frame with 25% overlap)\n",
    "            frame_length_ms = 5\n",
    "            hop_length_ms = 3.75  # 25% overlap\n",
    "            \n",
    "            frame_length = int(frame_length_ms * self.sample_rate / 1000)\n",
    "            hop_length = int(hop_length_ms * self.sample_rate / 1000)\n",
    "            \n",
    "            mfccs = librosa.feature.mfcc(\n",
    "                y=audio,\n",
    "                sr=self.sample_rate,\n",
    "                n_mfcc=40,\n",
    "                n_fft=frame_length,\n",
    "                hop_length=hop_length,\n",
    "                n_mels=40,\n",
    "                window='hamming'\n",
    "            )\n",
    "            \n",
    "            # Calculate Shannon entropy\n",
    "            shannon_entropy = self.calculate_shannon_entropy(audio)\n",
    "            \n",
    "            return mfccs, shannon_entropy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate_predictions_mean_based(folder_path, model_path, labeled_csv_path, output_csv_path):\n",
    "    # Load the trained model\n",
    "    input_size = 9  # Total features per frame\n",
    "    model = PyTorchModel(input_size=input_size)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # Load labeled data\n",
    "    labeled_data = pd.read_csv(labeled_csv_path)\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    filenames = []\n",
    "\n",
    "    # Initialize the feature extractor\n",
    "    feature_extractor = CoughFeatureExtractor()\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith((\".wav\", \".ogg\")):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            # Extract features using the feature extractor\n",
    "            mfccs, shannon_entropy = feature_extractor.calculate_mfcc_features(file_path)\n",
    "\n",
    "            # Skip if feature extraction failed\n",
    "            if mfccs is None or shannon_entropy is None:\n",
    "                print(f\"Skipping {file} due to feature extraction error.\")\n",
    "                continue\n",
    "\n",
    "            # Flatten the MFCCs and combine with Shannon entropy\n",
    "            mfccs_flat = mfccs.flatten()  # Flatten MFCCs into a 1D array\n",
    "            features = np.append(mfccs_flat, shannon_entropy)  # Combine with Shannon entropy\n",
    "\n",
    "            # Convert to tensor\n",
    "            features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "            # Predict for each frame\n",
    "            with torch.no_grad():\n",
    "                outputs = model(features_tensor.unsqueeze(0))  # Add batch dimension\n",
    "                frame_predictions = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            # Calculate mode (most frequent) of predictions\n",
    "            if len(frame_predictions) > 0:\n",
    "                mode_result = mode(frame_predictions)\n",
    "                \n",
    "                # Check if mode_result.mode is an array or scalar\n",
    "                if isinstance(mode_result.mode, np.ndarray):\n",
    "                    mean_prediction = int(mode_result.mode[0]) + 1  # Add 1 for mapping (1, 2, 3)\n",
    "                else:\n",
    "                    mean_prediction = int(mode_result.mode) + 1  # Add 1 for mapping (1, 2, 3)\n",
    "                    \n",
    "            else:\n",
    "                mean_prediction = -1  # Assign a default label if no predictions are available\n",
    "\n",
    "            # Extract file number from file name and match with labeled data\n",
    "            file_number = int(''.join(filter(str.isdigit, file)))  # Extract digits from the file name\n",
    "            true_label_row = labeled_data[labeled_data[\"file_number\"] == file_number]\n",
    "\n",
    "            # Get true label from labeled data\n",
    "            if not true_label_row.empty:\n",
    "                true_label = true_label_row[\"target\"].values[0]\n",
    "            else:\n",
    "                true_label = -1  # Assign a default label if no labels are found\n",
    "\n",
    "            # Append results\n",
    "            filenames.append(file)\n",
    "            true_labels.append(true_label)\n",
    "            predicted_labels.append(mean_prediction)\n",
    "            print(f\"Processed {file}: True Label = {true_label}, Predicted Label = {mean_prediction}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels)) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Filename\": filenames,\n",
    "        \"True Label\": true_labels,\n",
    "        \"Predicted Label\": predicted_labels\n",
    "    })\n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Results saved to {output_csv_path}\")\n",
    "\n",
    "# Paths and Configuration\n",
    "folder_path = r\"C:\\Users\\OM\\Desktop\\Anvesshan\\Final_supported_file1\"  # Path to folder containing audio files\n",
    "model_path = r\"C:\\Users\\OM\\Desktop\\Anvesshan\\modeified_files\\trained_model.pth\"  # Path to the trained model\n",
    "labeled_csv_path = r\"C:\\Users\\OM\\Desktop\\Anvesshan\\modeified_files\\labelled_data.csv\"  # Path to labeled CSV file\n",
    "output_csv_path = \"output.csv\"  # Output CSV file path\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_predictions_mean_based(folder_path, model_path, labeled_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
